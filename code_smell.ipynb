{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ast\n",
    "\n",
    "def parse_code_to_ast(code):\n",
    "    return ast.parse(code)\n",
    "\n",
    "\n",
    "from radon.complexity import cc_visit\n",
    "from radon.metrics import h_visit, HalsteadReport\n",
    "from radon.raw import analyze\n",
    "\n",
    "def extract_static_metrics(code):\n",
    "    metrics = {}\n",
    "    \n",
    "    complexity = cc_visit(code)\n",
    "    metrics['cyclomatic_complexity'] = sum([c.complexity for c in complexity])\n",
    "    \n",
    "    \n",
    "    halstead = h_visit(code)\n",
    "    metrics.update(halstead._asdict())\n",
    "\n",
    "    \n",
    "    raw = analyze(code)\n",
    "    metrics.update(raw._asdict())\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"huggingface/CodeBERTa-small-v1\")\n",
    "model = RobertaModel.from_pretrained(\"huggingface/CodeBERTa-small-v1\")\n",
    "\n",
    "def get_semantic_embedding(code):\n",
    "    inputs = tokenizer(code, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    embedding = outputs.last_hidden_state.mean(dim=1)  \n",
    "    return embedding.detach().numpy()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def flatten_halstead_report(report):\n",
    "    if isinstance(report, HalsteadReport):\n",
    "        return [\n",
    "            report.h1, report.h2, report.N1, report.N2, \n",
    "            report.vocabulary, report.length, report.calculated_length,\n",
    "            report.volume, report.difficulty, report.effort,\n",
    "            report.time, report.bugs\n",
    "        ]\n",
    "    return [0] * 12  \n",
    "\n",
    "def process_metrics(metrics):\n",
    "    \n",
    "    numeric_features = [\n",
    "        metrics.get('cyclomatic_complexity', 0),\n",
    "        metrics.get('loc', 0),\n",
    "        metrics.get('lloc', 0),\n",
    "        metrics.get('sloc', 0),\n",
    "        metrics.get('comments', 0),\n",
    "        metrics.get('multi', 0),\n",
    "        metrics.get('blank', 0),\n",
    "        metrics.get('single_comments', 0),\n",
    "    ]\n",
    "\n",
    "    \n",
    "    if 'total' in metrics:\n",
    "        numeric_features += flatten_halstead_report(metrics['total'])\n",
    "    else:\n",
    "        numeric_features += [0] * 12\n",
    "\n",
    "    \n",
    "    function_reports = metrics.get('functions', [])\n",
    "    if function_reports:\n",
    "        for func_name, report in function_reports:\n",
    "            numeric_features += flatten_halstead_report(report)\n",
    "    else:\n",
    "        \n",
    "        numeric_features += [0] * 12\n",
    "\n",
    "    return np.array(numeric_features)\n",
    "\n",
    "def combine_features(metrics, embedding):\n",
    "    \n",
    "    metrics_vector = process_metrics(metrics)\n",
    "    \n",
    "    \n",
    "    feature_vector = np.concatenate([metrics_vector, embedding.flatten()])\n",
    "    \n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def reduce_dimensions(features, n_components=20):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "    return reduced_features\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "def build_graph(tree, features):\n",
    "    graph = nx.DiGraph()\n",
    "    nodes = list(ast.walk(tree))  \n",
    "\n",
    "    \n",
    "    if len(features) != len(nodes):\n",
    "        raise ValueError(\"The number of features does not match the number of AST nodes.\")\n",
    "\n",
    "    \n",
    "    for i, node in enumerate(nodes):\n",
    "        graph.add_node(i, features=features[i])  \n",
    "\n",
    "    \n",
    "    for parent_index, parent_node in enumerate(nodes):\n",
    "        for child_node in ast.iter_child_nodes(parent_node):\n",
    "            child_index = nodes.index(child_node)  \n",
    "            graph.add_edge(parent_index, child_index)\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "\n",
    "def optimize_graph(graph):\n",
    "    \n",
    "    isolated_nodes = list(nx.isolates(graph))\n",
    "    graph.remove_nodes_from(isolated_nodes)\n",
    "    return graph\n",
    "\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def create_graph_data(graph):\n",
    "    edge_index = torch.tensor(list(graph.edges)).t().contiguous()\n",
    "    x = torch.tensor([graph.nodes[n]['features'] for n in graph.nodes], dtype=torch.float)\n",
    "    y = torch.zeros(len(graph.nodes))  \n",
    "    return Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "\n",
    "code = \"\"\"\n",
    "def example_function(a, b):\n",
    "    result = a + b\n",
    "    if result > 10:\n",
    "        return \"Large\"\n",
    "    else:\n",
    "        return \"Small\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "tree = parse_code_to_ast(code)\n",
    "metrics = extract_static_metrics(code)\n",
    "embedding = get_semantic_embedding(code)\n",
    "feature_vector = combine_features(metrics, embedding)\n",
    "\n",
    "\n",
    "features = [feature_vector] * len(list(ast.walk(tree)))  \n",
    "reduced_features = reduce_dimensions(np.array(features))\n",
    "\n",
    "\n",
    "graph = build_graph(tree, reduced_features)\n",
    "optimized_graph = optimize_graph(graph)\n",
    "\n",
    "\n",
    "graph_data = create_graph_data(optimized_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0: Smelly\n",
      "Node 1: Smelly\n",
      "Node 2: Smelly\n",
      "Node 3: Smelly\n",
      "Node 4: Smelly\n",
      "Node 5: Smelly\n",
      "Node 6: Smelly\n",
      "Node 7: Smelly\n",
      "Node 8: Smelly\n",
      "Node 9: Smelly\n",
      "Node 10: Smelly\n",
      "Node 11: Smelly\n",
      "Node 12: Smelly\n",
      "Node 13: Smelly\n",
      "Node 14: Smelly\n",
      "Node 15: Smelly\n",
      "Node 16: Smelly\n",
      "Node 17: Smelly\n",
      "Node 18: Smelly\n",
      "Node 19: Smelly\n",
      "Node 20: Smelly\n",
      "Node 21: Smelly\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCNClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCNClassifier, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "def predict(data, model):\n",
    "    with torch.no_grad():\n",
    "        logits = model(data)  \n",
    "        predictions = torch.argmax(logits, dim=1)  \n",
    "    return predictions\n",
    "\n",
    "\n",
    "input_dim = graph_data.x.shape[1]  \n",
    "hidden_dim = 16  \n",
    "output_dim = 2  \n",
    "\n",
    "\n",
    "model = GCNClassifier(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "predictions = predict(graph_data, model)\n",
    "\n",
    "\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f\"Node {i}: {'Smelly' if prediction.item() == 1 else 'Not Smelly'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
